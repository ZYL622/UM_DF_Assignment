{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "3ff57103",
      "metadata": {
        "id": "3ff57103"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from keras.layers import Dense, Dropout\n",
        "from tensorflow.keras import regularizers\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os\n",
        "import cv2\n",
        "import sklearn\n",
        "import imageio\n",
        "from skimage.io import imread\n",
        "from skimage.transform import resize\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import math \n",
        "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive # 此时colab中出现drive的文件夹，里面就是你的google drive的根目录文件\n",
        "# Load the images and their labels into two lists\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "os.chdir(\"/content/drive/MyDrive\") "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rz1Hc-e8RZRv",
        "outputId": "9f084888-e5d3-4bc0-9722-7418c5840da6"
      },
      "id": "rz1Hc-e8RZRv",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: google-drive-ocamlfuse: command not found\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca7f3f8f",
      "metadata": {
        "id": "ca7f3f8f"
      },
      "source": [
        "Load and preprocessing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "d0731166",
      "metadata": {
        "id": "d0731166"
      },
      "outputs": [],
      "source": [
        "# Loads labels\n",
        "df = pd.read_csv(\"seedling_labels.csv\")\n",
        "# df[\"average_expert\"] = (df[\"Expert 1\"] + df[\"Expert 2\"]  + df[\"Expert 3\"] + df[\"Expert 4\"]) / 4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images = []\n",
        "labels = []\n",
        "for i in range(len(df)):\n",
        "    color_cam_path = df.loc[i, 'color_cam_path']\n",
        "    \n",
        "    label = 1 if df.loc[i, 'Expert 1'] > 2 else 0\n",
        "    \n",
        "    image_color = imageio.imread(color_cam_path, as_gray=False) \n",
        "    image_color_resized = cv2.resize(image_color, (180, 180)) # Resize the image to a consistent size\n",
        "    # image_color_resized = cv2.resize(image_color, (180, 180))/255 # normalize the figure\n",
        "\n",
        "    images.append(image_color_resized)\n",
        "    labels.append(label)"
      ],
      "metadata": {
        "id": "C8phb11IUIHV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d159f8b-f081-4ba7-a563-740a356fc1ec"
      },
      "id": "C8phb11IUIHV",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-3438aac86d2d>:9: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  image_color = imageio.imread(color_cam_path, as_gray=False)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train"
      ],
      "metadata": {
        "id": "ozG2MtdeXPkd"
      },
      "id": "ozG2MtdeXPkd"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ff499d59",
      "metadata": {
        "id": "ff499d59"
      },
      "outputs": [],
      "source": [
        "# Split the data into training and test sets\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(nor_images, nor_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Split the training set into training and validation sets\n",
        "train_images, val_images, train_labels, val_labels = train_test_split(train_images, train_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert the lists to tensors\n",
        "train_images = tf.convert_to_tensor(train_images)\n",
        "train_labels = tf.convert_to_tensor(train_labels)\n",
        "val_images = tf.convert_to_tensor(val_images)\n",
        "val_labels = tf.convert_to_tensor(val_labels)\n",
        "test_images = tf.convert_to_tensor(test_images)\n",
        "test_labels = tf.convert_to_tensor(test_labels)\n",
        "\n",
        "# Create datasets from the tensors\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
        "val_ds = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
        "\n",
        "# Shuffle and batch the datasets\n",
        "batch_size = 16\n",
        "train_ds = train_ds.shuffle(buffer_size=len(train_images)).batch(batch_size)\n",
        "val_ds = val_ds.shuffle(buffer_size=len(val_images)).batch(batch_size)\n",
        "test_ds = test_ds.shuffle(buffer_size=len(test_images)).batch(batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c27c645f",
      "metadata": {
        "id": "c27c645f"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(180, 180, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "class_weight = {0: 1.0, 1: 2.0}\n",
        "model.fit(train_ds, epochs=11, class_weight=class_weight, verbose=1, validation_data=val_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "28dbc4ff",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28dbc4ff",
        "outputId": "92190159-7e63-435e-d0b2-947bf8fe5406"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13/13 [==============================] - 2s 136ms/step - loss: 0.4208 - accuracy: 0.8090\n",
            "Test loss: 0.42075392603874207, Test accuracy: 0.8090452551841736\n"
          ]
        }
      ],
      "source": [
        "loss, accuracy = model.evaluate(test_ds, verbose=1)\n",
        "print(f'Test loss: {loss}, Test accuracy: {accuracy}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model.save('expert_ave_color_model.h5')"
      ],
      "metadata": {
        "id": "7nLe4rerZyCb"
      },
      "id": "7nLe4rerZyCb",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p saved_model\n",
        "model.save('saved_model/expert_1_color_model.h5') "
      ],
      "metadata": {
        "id": "Ed56mf0GaaSo"
      },
      "id": "Ed56mf0GaaSo",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Check"
      ],
      "metadata": {
        "id": "UOfjcswbK1Ms"
      },
      "id": "UOfjcswbK1Ms"
    },
    {
      "cell_type": "code",
      "source": [
        "# model check\n",
        "all_train_data = tf.convert_to_tensor(nor_images)"
      ],
      "metadata": {
        "id": "wYRomqVmI8GQ"
      },
      "id": "wYRomqVmI8GQ",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pre_1 = model.predict(all_train_data, verbose=1)\n",
        "\n",
        "pre_list_1 = turn_bin(pre_1)\n",
        "\n",
        "label_1 = [] # conclusion of expert 1\n",
        "for i in range(len(df)):\n",
        "  label_1.append(1 if df.loc[i, 'Expert 1'] > 2 else 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CApLEYRbJW9I",
        "outputId": "3a3515de-0d2b-4df1-ffe2-42ec09e1c078"
      },
      "id": "CApLEYRbJW9I",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 12s 365ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc_single_1 = acc(pre_list_1, label_1)\n",
        "acc_single_1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iSaypsvJrAI",
        "outputId": "c8d793fa-f2c7-48d6-9508-f791d99e5d22"
      },
      "id": "-iSaypsvJrAI",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.852112676056338"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# previous model check\n",
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive # 此时colab中出现drive的文件夹，里面就是你的google drive的根目录文件\n",
        "# Load the images and their labels into two lists\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "import os\n",
        "os.chdir(\"/content/drive/MyDrive/saved_model/\") \n",
        "\n",
        "loaded_model2 = tf.keras.models.load_model('expert_2_color_model.h5')\n",
        "all_train_data = tf.convert_to_tensor(images)\n",
        "\n",
        "pre_2 = loaded_model2.predict(all_train_data, verbose=1)\n",
        "pre_list_2 = turn_bin(pre_2)\n",
        "\n",
        "label_2 = [] # conclusion of expert 2\n",
        "for i in range(len(df)):\n",
        "  label_2.append(1 if df.loc[i, 'Expert 2'] > 2 else 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-sw1RUzKAyC",
        "outputId": "3b30f1e4-7fc5-403e-b614-19cdf0eb80b7"
      },
      "id": "1-sw1RUzKAyC",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: google-drive-ocamlfuse: command not found\n",
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n",
            "32/32 [==============================] - 10s 299ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc_single_2 = acc(pre_list_2, label_2)\n",
        "acc_single_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YuMCdsLRKgpd",
        "outputId": "47da291d-a71f-4559-a675-6f2076be7049"
      },
      "id": "YuMCdsLRKgpd",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9265593561368209"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# High-level data fusion"
      ],
      "metadata": {
        "id": "6cnIUjeiZdQA"
      },
      "id": "6cnIUjeiZdQA"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Check"
      ],
      "metadata": {
        "id": "phy0Sk9WWfEv"
      },
      "id": "phy0Sk9WWfEv"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "3966692c",
      "metadata": {
        "id": "3966692c"
      },
      "outputs": [],
      "source": [
        "model.save('expert4_color_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "f4c6511f",
      "metadata": {
        "id": "f4c6511f"
      },
      "outputs": [],
      "source": [
        "loaded_model = tf.keras.models.load_model('expert4_color_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "80c4206e",
      "metadata": {
        "id": "80c4206e",
        "outputId": "dc29951b-1d66-4564-d580-df3abb0dc565",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13/13 [==============================] - 4s 257ms/step\n",
            "[[139   0]\n",
            " [ 60   0]]\n"
          ]
        }
      ],
      "source": [
        "# Get the true labels and predicted labels for the test dataset\n",
        "y_test = np.concatenate([y for x, y in test_ds], axis=0)\n",
        "y_pred = np.round(model.predict(test_ds))\n",
        "\n",
        "# Compute the confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "312d50a5",
      "metadata": {
        "id": "312d50a5",
        "outputId": "c7afdec4-1374-4031-9314-9ae8a99651e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13/13 [==============================] - 3s 200ms/step\n"
          ]
        }
      ],
      "source": [
        "model1_predictions = model.predict(test_ds)\n",
        "model1_predicted_labels = np.array((model1_predictions > 0.6).astype(int)).flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "f61e482d",
      "metadata": {
        "id": "f61e482d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aee56759-6278-4645-d698-9c2a1cfe3adb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        }
      ],
      "source": [
        "# Get the actual labels of the dataset\n",
        "actual_labels_ds = test_ds.map(lambda x, y: y)\n",
        "actual_labels = np.concatenate(list(actual_labels_ds.as_numpy_iterator()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "02636c4d",
      "metadata": {
        "id": "02636c4d",
        "outputId": "c4e8b55d-81e3-4e51-cbbc-3492ee743195",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The overall accurancy: 0.6984924623115578\n"
          ]
        }
      ],
      "source": [
        "correct_predictions = 0\n",
        "total_predictions = 0\n",
        "for actual_label, balanced_predicted_label in zip(actual_labels, model1_predicted_labels ):\n",
        "    if actual_label == balanced_predicted_label:\n",
        "        correct_predictions += 1\n",
        "    total_predictions += 1\n",
        "\n",
        "\n",
        "accuracy = correct_predictions / total_predictions\n",
        "print(\"The overall accurancy:\", accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5b7391a",
      "metadata": {
        "id": "f5b7391a"
      },
      "source": [
        "# Load all the models"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive # 此时colab中出现drive的文件夹，里面就是你的google drive的根目录文件\n",
        "# Load the images and their labels into two lists\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "import os\n",
        "os.chdir(\"/content/drive/MyDrive/saved_model/\") "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbDdNabMFDJe",
        "outputId": "1e2cf9d6-db44-422b-d48c-6eaf8fadb773"
      },
      "id": "IbDdNabMFDJe",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: google-drive-ocamlfuse: command not found\n",
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "c52e7f96",
      "metadata": {
        "id": "c52e7f96"
      },
      "outputs": [],
      "source": [
        "loaded_model1 = tf.keras.models.load_model('expert_1_color_model.h5')\n",
        "loaded_model2 = tf.keras.models.load_model('expert_2_color_model.h5')\n",
        "loaded_model3 = tf.keras.models.load_model('expert_3_color_model.h5')\n",
        "loaded_model4 = tf.keras.models.load_model('expert_4_color_model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Single model"
      ],
      "metadata": {
        "id": "wGYd7ittPMH8"
      },
      "id": "wGYd7ittPMH8"
    },
    {
      "cell_type": "code",
      "source": [
        "all_train_data = tf.convert_to_tensor(images)"
      ],
      "metadata": {
        "id": "7YHBTKJPepGp"
      },
      "id": "7YHBTKJPepGp",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pre_1 = loaded_model1.predict(all_train_data, verbose=1)\n",
        "pre_2 = loaded_model2.predict(all_train_data, verbose=1)\n",
        "pre_3 = loaded_model3.predict(all_train_data, verbose=1)\n",
        "pre_4 = loaded_model4.predict(all_train_data, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPfqeywxRuG3",
        "outputId": "e0023da1-296b-4902-ead9-b11136ac1db7"
      },
      "id": "nPfqeywxRuG3",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 10s 300ms/step\n",
            "32/32 [==============================] - 10s 298ms/step\n",
            "32/32 [==============================] - 9s 274ms/step\n",
            "32/32 [==============================] - 8s 254ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def turn_bin(data_array):\n",
        "  list_bin = []\n",
        "  for i in range(len(data_array)):\n",
        "    if data_array[i][0] >= 0.5:\n",
        "      list_bin.append(1)\n",
        "    else:\n",
        "      list_bin.append(0)\n",
        "  return list_bin\n",
        "\n",
        "def acc(pre_list, test_list):\n",
        "  un_match = 0\n",
        "  total = len(pre_list)\n",
        "  for i in range(len(pre_list)):\n",
        "    if pre_list[i] != test_list[i]:\n",
        "      un_match += 1\n",
        "  wrong_per = un_match / total\n",
        "  return(1-wrong_per)"
      ],
      "metadata": {
        "id": "IgdPCubKXPUj"
      },
      "id": "IgdPCubKXPUj",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pre_list_1 = turn_bin(pre_1)\n",
        "pre_list_2 = turn_bin(pre_2)\n",
        "pre_list_3 = turn_bin(pre_3)\n",
        "pre_list_4 = turn_bin(pre_4)"
      ],
      "metadata": {
        "id": "w85Gtne_WvMe"
      },
      "id": "w85Gtne_WvMe",
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_1 = [] # conclusion of expert 1\n",
        "label_2 = []\n",
        "label_3 = []\n",
        "label_4 = []\n",
        "for i in range(len(df)):\n",
        "  label_1.append(1 if df.loc[i, 'Expert 1'] > 2 else 0)\n",
        "  label_2.append(1 if df.loc[i, 'Expert 2'] > 2 else 0)\n",
        "  label_3.append(1 if df.loc[i, 'Expert 3'] > 2 else 0)\n",
        "  label_4.append(1 if df.loc[i, 'Expert 4'] > 2 else 0)"
      ],
      "metadata": {
        "id": "qEB7Jh0hSmWx"
      },
      "id": "qEB7Jh0hSmWx",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check acc\n",
        "acc_single_1 = acc(pre_list_1, label_1)\n",
        "acc_single_2 = acc(pre_list_2, label_2)\n",
        "acc_single_3 = acc(pre_list_3, label_3)\n",
        "acc_single_4 = acc(pre_list_4, label_4)\n",
        "\n",
        "acc_single_1, acc_single_2, acc_single_3, acc_single_4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zb_L2ohNYUfT",
        "outputId": "eba4bdcf-7b03-4245-8a56-330ae85b6c03"
      },
      "id": "Zb_L2ohNYUfT",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9175050301810865,\n",
              " 0.9265593561368209,\n",
              " 0.9356136820925554,\n",
              " 0.9366197183098591)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_true = []\n",
        "for i in range(len(label_4)):\n",
        "  if label_1[i] + label_2[i] + label_3[i] + label_4[i] > 2:\n",
        "    label_true.append(1) # normal\n",
        "  elif label_1[i] + label_2[i] + label_3[i] + label_4[i] < 2:\n",
        "    label_true.append(0) # abnormal\n",
        "  else:\n",
        "    label_true.append(3)"
      ],
      "metadata": {
        "id": "ZEkLyaH5TxqR"
      },
      "id": "ZEkLyaH5TxqR",
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Majory Voting"
      ],
      "metadata": {
        "id": "uUEaBcIDN9rE"
      },
      "id": "uUEaBcIDN9rE"
    },
    {
      "cell_type": "code",
      "source": [
        "def major_vote(test_list, pre_list_1, pre_list_2, pre_list_3, pre_list_4):\n",
        "  wrong_num = 0\n",
        "  un_decide = 0\n",
        "  true_undecide = 0\n",
        "  for i in range(len(test_list)):\n",
        "    if pre_list_1[i] + pre_list_2[i] + pre_list_3[i] + pre_list_4[i] > 2: # more normal case\n",
        "      now_pre = 1\n",
        "      if test_list[i] != now_pre:\n",
        "        wrong_num += 1\n",
        "    if pre_list_1[i] + pre_list_2[i] + pre_list_3[i] + pre_list_4[i] < 2:\n",
        "      now_pre = 0\n",
        "      if test_list[i] != now_pre:\n",
        "        wrong_num += 1\n",
        "    if pre_list_1[i] + pre_list_2[i] + pre_list_3[i] + pre_list_4[i] == 2:\n",
        "      un_decide += 1\n",
        "      if test_list[i] == 3:\n",
        "        true_undecide += 1\n",
        "    # print(now_pre)\n",
        "  return (1-wrong_num / len(test_list)), un_decide / len(test_list), true_undecide"
      ],
      "metadata": {
        "id": "tIb6bNx4PPQD"
      },
      "id": "tIb6bNx4PPQD",
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "un_decide_index = []\n",
        "for i in range(len(label_true)):\n",
        "  if label_true[i] == 3:\n",
        "    un_decide_index.append(i)\n",
        "len(un_decide_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4DAgfRmb9br",
        "outputId": "7de60731-0eff-4f3b-e64c-95660cbbea76"
      },
      "id": "S4DAgfRmb9br",
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "major_vote(label_true, pre_list_1, pre_list_2, pre_list_3, pre_list_4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKmALQDhbcgK",
        "outputId": "a1bdc93b-f974-453e-97b9-3546e5c78e9e"
      },
      "id": "pKmALQDhbcgK",
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9527162977867203, 0.04426559356136821, 11)"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc_single_1, acc_single_2, acc_single_3, acc_single_4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bo9S8Pypbpte",
        "outputId": "ecafd19e-6db9-4f8f-f312-8de2dfdec147"
      },
      "id": "Bo9S8Pypbpte",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9175050301810865,\n",
              " 0.9265593561368209,\n",
              " 0.9356136820925554,\n",
              " 0.9366197183098591)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Weighted Voting"
      ],
      "metadata": {
        "id": "ZSwVxS-lQPOy"
      },
      "id": "ZSwVxS-lQPOy"
    },
    {
      "cell_type": "code",
      "source": [
        "sum_acc = sum([acc_single_1, acc_single_2, acc_single_3, acc_single_4])\n",
        "def wei(acc, sum_acc):\n",
        "  return acc / sum_acc\n",
        "\n",
        "wei_1 = wei(acc_single_1, sum_acc)\n",
        "wei_2 = wei(acc_single_2, sum_acc)\n",
        "wei_3 = wei(acc_single_3, sum_acc)\n",
        "wei_4 = wei(acc_single_4, sum_acc)"
      ],
      "metadata": {
        "id": "Ab9y_X7GQO7B"
      },
      "id": "Ab9y_X7GQO7B",
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wei_1, wei_2, wei_3, wei_4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7FNJUQVZPqHb",
        "outputId": "9065ea6f-de73-4545-e488-ab014d3aced0"
      },
      "id": "7FNJUQVZPqHb",
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.24688684353004875,\n",
              " 0.24932322685435843,\n",
              " 0.2517596101786681,\n",
              " 0.2520303194369247)"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def weight_vote(test_list, pre_list_1, pre_list_2, pre_list_3, pre_list_4):\n",
        "  wrong_num = 0\n",
        "  un_decide = 0\n",
        "  for i in range(len(test_list)):\n",
        "    if wei_1 * pre_list_1[i] + wei_2 * pre_list_2[i] + wei_3 * pre_list_3[i] + wei_4 * pre_list_4[i] > 0.5:\n",
        "      now_pre = 1\n",
        "      if test_list[i] != now_pre:\n",
        "        wrong_num += 1\n",
        "    if wei_1 * pre_list_1[i] + wei_2 * pre_list_2[i] + wei_3 * pre_list_3[i] + wei_4 * pre_list_4[i] < 0.5:\n",
        "      now_pre = 0\n",
        "      if test_list[i] != now_pre:\n",
        "        wrong_num += 1\n",
        "    if wei_1 * pre_list_1[i] + wei_2 * pre_list_2[i] + wei_3 * pre_list_3[i] + wei_4 * pre_list_4[i] == 0.5:\n",
        "      un_decide += 1\n",
        "  return (1- wrong_num / len(test_list)), un_decide / len(test_list)"
      ],
      "metadata": {
        "id": "9VfdqvS0Q_hn"
      },
      "id": "9VfdqvS0Q_hn",
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weight_vote(label_true, pre_list_1, pre_list_2, pre_list_3, pre_list_4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHLmeq3FePJ2",
        "outputId": "41a8dbd7-3d3e-46d3-fe2b-e20e75f9b6f6"
      },
      "id": "FHLmeq3FePJ2",
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9255533199195171, 0.0)"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bayesian Consensus"
      ],
      "metadata": {
        "id": "5bJizAnaWvtv"
      },
      "id": "5bJizAnaWvtv"
    },
    {
      "cell_type": "code",
      "source": [
        "# combine the prediction results of three methods\n",
        "y_pred_single = {'exp1':pre_list_1, 'exp2':pre_list_2,\n",
        "                 'exp3':pre_list_3, \"exp4\":pre_list_4}"
      ],
      "metadata": {
        "id": "-F2X7NgUWw4o"
      },
      "id": "-F2X7NgUWw4o",
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model_num(model_num):\n",
        "  # model_num is i-th method (from 0)\n",
        "  model_list = ['exp1', 'exp2', 'exp3', 'exp4']\n",
        "  # model_list = ['svm', 'dt', 'lr']\n",
        "  return model_list[model_num] # return the name of model\n",
        "\n",
        "def cal_p(model_num, cal_val, p_now, pred_val): \n",
        "  ## calculate the probability of p_now[0], namely 0\n",
        "  # model_num will choose the model considering now (from 0)\\\n",
        "  # cal_val is the condition we consider, namely 0\n",
        "  # p_now is the prior probability using now\n",
        "  # pred_val is the predition of the model_num (about this sample) = given condition when calculating\n",
        "  name_model = get_model_num(model_num)\n",
        "  upper = p_now[cal_val] * prob_record[name_model][cal_val][pred_val] # key: method - true - prediction \n",
        "  lower = upper + (1 - p_now[cal_val]) * prob_record[name_model][1 - cal_val][pred_val]\n",
        "  p_result = upper / lower\n",
        "  return p_result"
      ],
      "metadata": {
        "id": "puD1vFpTW0RJ"
      },
      "id": "puD1vFpTW0RJ",
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### calculate likelihood prob.\n",
        "prob_model_true_pred = {'exp1':{}, 'exp2':{}, 'exp3':{}, 'exp4':{}}\n",
        "\n",
        "def cal_likelihood_prob(model_num, y_test, true_val):\n",
        "  # true_value_list here is [0,1]\n",
        "  model_name = get_model_num(model_num)\n",
        "  # print(model_name)\n",
        "  y_pred = y_pred_single[model_name]\n",
        "  list_y_test = y_test #.values\n",
        "  \n",
        "  num_r = 0\n",
        "  num_f = 0\n",
        "  for i in range(len(y_pred)):\n",
        "    if list_y_test[i] == true_val:\n",
        "      # true a or true b\n",
        "      if y_pred[i] == list_y_test[i]:\n",
        "      # the predition is same as true value\n",
        "        num_r += 1\n",
        "      else:\n",
        "        num_f += 1\n",
        "\n",
        "  percent_r = num_r / (num_r + num_f)\n",
        "  percent_f = 1 - percent_r\n",
        "  return percent_r, percent_f\n",
        "\n",
        "## Model - exp1\n",
        "# predict as 0-bad, prior output should be same as the prediction\n",
        "percent_p0_t0_dt, percent_p1_t0_dt = cal_likelihood_prob(model_num=0, y_test=label_true, true_val=0)\n",
        "# predict as 1-good \n",
        "percent_p1_t1_dt, percent_p0_t1_dt = cal_likelihood_prob(model_num=0, y_test=label_true, true_val=1)\n",
        "\n",
        "## Model - exp2\n",
        "# predict as 0-bad\n",
        "percent_p0_t0_svm, percent_p1_t0_svm = cal_likelihood_prob(model_num=1, y_test=label_true, true_val=0)\n",
        "# predict as 1-good\n",
        "percent_p1_t1_svm, percent_p0_t1_svm = cal_likelihood_prob(model_num=1, y_test=label_true, true_val=1)\n",
        "\n",
        "## Model - exp3\n",
        "# predict as 0-bad \n",
        "percent_p0_t0_lr, percent_p1_t0_lr = cal_likelihood_prob(model_num=2, y_test=label_true, true_val=0)\n",
        "# predict as 1-good\n",
        "percent_p1_t1_lr, percent_p0_t1_lr = cal_likelihood_prob(model_num=2, y_test=label_true, true_val=1)\n",
        "\n",
        "## Model - exp4\n",
        "# predict as 0-bad \n",
        "percent_p0_t0_4, percent_p1_t0_4 = cal_likelihood_prob(model_num=3, y_test=label_true, true_val=0)\n",
        "# predict as 1-good\n",
        "percent_p1_t1_4, percent_p0_t1_4 = cal_likelihood_prob(model_num=3, y_test=label_true, true_val=1)"
      ],
      "metadata": {
        "id": "2V76kEPsW1vF"
      },
      "id": "2V76kEPsW1vF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prob_result = {'dt_true_0':{'pred_0':percent_p0_t0_dt, 'pred_1':percent_p1_t0_dt},\n",
        "#          'dt_true_1':{'pred_0':percent_p0_t1_dt, 'pred_1':percent_p1_t1_dt},\n",
        "#          'svm_true_0':{'pred_0':percent_p0_t0_svm, 'pred_1':percent_p1_t0_svm},\n",
        "#          'svm_true_1':{'pred_0':percent_p0_t1_svm, 'pred_1':percent_p1_t1_svm},\n",
        "#          'lr_true_0':{'pred_0':percent_p0_t0_lr, 'pred_1':percent_p1_t0_lr},\n",
        "#          'lr_true_1':{'pred_0':percent_p0_t1_lr, 'pred_1':percent_p1_t1_lr}}\n",
        "\n",
        "y_test_val = label_true #.values\n",
        "\n",
        "prob_record = {'exp1':{0:{0:percent_p0_t0_dt, 1:percent_p1_t0_dt},\n",
        "         1:{0:percent_p0_t1_dt, 1:percent_p1_t1_dt}},\n",
        "         'exp2':{0:{0:percent_p0_t0_svm, 1:percent_p1_t0_svm},\n",
        "         1:{0:percent_p0_t1_svm, 1:percent_p1_t1_svm}},\n",
        "         'exp3':{0:{0:percent_p0_t0_lr, 1:percent_p1_t0_lr},\n",
        "         1:{0:percent_p0_t1_lr, 1:percent_p1_t1_lr}},\n",
        "         'exp4':{0:{0:percent_p0_t0_4, 1:percent_p1_t0_4}, \n",
        "         1:{0:percent_p0_t1_4, 1:percent_p1_t1_4}}\n",
        "         }\n",
        "# key: method - true - prediction "
      ],
      "metadata": {
        "id": "x7ss0tf0W1p1"
      },
      "id": "x7ss0tf0W1p1",
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prob_record"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZrJwLmoW59t",
        "outputId": "e21ebaf5-611f-4e6d-afe6-a7961142d501"
      },
      "id": "nZrJwLmoW59t",
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'exp1': {0: {0: 0.9681620839363242, 1: 0.03183791606367581},\n",
              "  1: {0: 0.18214285714285716, 1: 0.8178571428571428}},\n",
              " 'exp2': {0: {0: 0.9232995658465991, 1: 0.07670043415340089},\n",
              "  1: {0: 0.07499999999999996, 1: 0.925}},\n",
              " 'exp3': {0: {0: 0.9421128798842258, 1: 0.05788712011577424},\n",
              "  1: {0: 0.10357142857142854, 1: 0.8964285714285715}},\n",
              " 'exp4': {0: {0: 0.934876989869754, 1: 0.06512301013024602},\n",
              "  1: {0: 0.05714285714285716, 1: 0.9428571428571428}}}"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_true0_pre0 = 0\n",
        "num_true0_pred1 = 0\n",
        "for i in range(len(label_true)):\n",
        "  if label_true[i] == 0: # true 0\n",
        "    if pre_list_1[i] == 0:\n",
        "      num_true0_pre0 += 1\n",
        "    else: \n",
        "      num_true0_pred1 += 1\n",
        "num_true0_pre0 / (num_true0_pre0 + num_true0_pred1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1uWBI2aXC8K",
        "outputId": "bdb57645-8c98-4aab-af40-8ff9b4804d55"
      },
      "id": "O1uWBI2aXC8K",
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9681620839363242"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "diff_i = []\n",
        "for i in range(len(pre_list_1)):\n",
        "  if pre_list_1[i]+ pre_list_2[i]+ pre_list_3[i]+ pre_list_4[i] not in [0,4]:\n",
        "    diff_i.append(i)\n",
        "    # print(y_test_val[i], y_pred_dt[i], y_pred_svm[i], y_pred_lr[i])\n"
      ],
      "metadata": {
        "id": "PjirpQENXEv2"
      },
      "id": "PjirpQENXEv2",
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "diff_i"
      ],
      "metadata": {
        "id": "GJuhsHwidEbL"
      },
      "id": "GJuhsHwidEbL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_method = 4\n",
        "y_test = label_true\n",
        "y_pred_bay = np.zeros(len(y_test))\n",
        "\n",
        "\n",
        "for sample_i in range(len(y_test)): # len(y_test)\n",
        "  p_update = {0:0.5, 1:0.5} # [0, 1]\n",
        "  for num_model in range(num_method):\n",
        "    name_model = get_model_num(num_model)\n",
        "    p_update[0] = cal_p(model_num=num_model, cal_val=0, p_now=p_update, pred_val=y_pred_single[name_model][sample_i])\n",
        "    p_update[1] = 1 - p_update[0]\n",
        "    if sample_i == 10:\n",
        "      print(p_update)\n",
        "  # choose the predition result with higher prob.\n",
        "  y_pred_bay[sample_i] = max(p_update, key=lambda x:p_update[x])\n",
        "\n",
        "## show result\n",
        "print(\"Accuracy of Bayesian Consensus:\", metrics.accuracy_score(y_test, y_pred_bay))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0b4QGa3QXICz",
        "outputId": "568e85bf-c603-45d0-dcf5-41e2a6f37961"
      },
      "id": "0b4QGa3QXICz",
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 0.8416568940649978, 1: 0.15834310593500223}\n",
            "{0: 0.9849479385730381, 1: 0.015052061426961916}\n",
            "{0: 0.9983227773769688, 1: 0.0016772226230311604}\n",
            "{0: 0.9998973207667026, 1: 0.00010267923329743134}\n",
            "Accuracy of Bayesian Consensus: 0.9195171026156942\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}